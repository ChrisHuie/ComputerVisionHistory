{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propogation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **forward propagation**, we apply a set of weights to the input data and calculate an output. For the first forward propagation, the set of weights is selected randomly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://imgur.com/aTFz1Az.png \"input values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now **randomly** assign weights to all of the synapses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://imgur.com/Su6Y4UC.png \"weights added\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sum the product of the inputs with their corresponding set of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 * 0.8 + 1 * 0.2 = 1\n",
    "1 * 0.4 + 1 * 0.9 = 1.3\n",
    "1 * 0.3 + 1 * 0.5 = 0.8  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://imgur.com/gTvxRwo.png \"sum of products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/800/1*DHN75JRJ_EQgGc0spfqLtQ.png \"sigmoid function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/800/0*5euYS7InCmDP08ir. \"sigmoid graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What makes this a good classifier over a step function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) You will notice the Y values are relatively steep which means, any small changes in the values of X in that region will cause values of Y to change significantly. This tends to bring Y values to either end of the curve which can make predictions more distinct.   \n",
    "\n",
    "2) The output of the activation function is always going to be in range (0,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigmoid(1.0) = 0.73105857863\n",
    "Sigmoid(1.3) = 0.78583498304\n",
    "Sigmoid(0.8) = 0.68997448112"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://imgur.com/yE88Ryt.png \"sigmoid activation calc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we sum the product of the hidden layer results with the second set of **random** weights and pass through our activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.73 * 0.3 + 0.79 * 0.5 + 0.69 * 0.9 = 1.235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigmoid(1.235) = 0.7746924929149283"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://imgur.com/IDFRq5a.png \"final diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropogation Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://media.giphy.com/media/11rIergnpiYpvW/giphy.gif \"sum of products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to figure out just how wrong our predictions are. Then, we adjust the weights accordingly so that the margin of errors are decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://imgur.com/kEyDCJ8.png \"backprop first step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://i.imgur.com/4qnVb6S.png \"delta output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://i.imgur.com/ByyQIJ8.png \"derivative graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden result 1 = 0.73105857863\n",
    "hidden result 2 = 0.78583498304\n",
    "hidden result 3 = 0.68997448112\n",
    "\n",
    "Delta weights = delta output sum / hidden layer results\n",
    "Delta weights = -0.1344 / [0.73105, 0.78583, 0.69997]\n",
    "Delta weights = [-0.1838, -0.1710, -0.1920]\n",
    "\n",
    "old w7 = 0.3\n",
    "old w8 = 0.5\n",
    "old w9 = 0.9\n",
    "\n",
    "new w7 = 0.1162\n",
    "new w8 = 0.329\n",
    "new w9 = 0.708"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](http://i.imgur.com/UNlffE1.png \"final backprop diagram\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
